{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Captcha Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rIe-ONdhFTv64vKW9tkqN3XAOw9xmwsR",
      "authorship_tag": "ABX9TyN7XRwnlChb9WSRzXw9fP5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azeem110201/Captcha-Recognition/blob/master/Captcha_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZjuooOEwFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYJE7eaLE60m",
        "colab_type": "text"
      },
      "source": [
        "Dataset can be downloaded from kaggle \n",
        "\n",
        "https://www.kaggle.com/fournierp/captcha-version-2-images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Rh0A_GEx-k",
        "colab_type": "text"
      },
      "source": [
        "Link to blog for CTC Loss \n",
        "\n",
        "https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjNNSNR4kh_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0a882333-0d82-4639-fc8a-c241fd7c2d62"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8OWGKYwt3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = Path(\"/content/drive/My Drive/captcha recognition/samples\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUCB_EgAw0mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "198d2f3b-209c-415f-ccb5-0861ddb66058"
      },
      "source": [
        "images = list(data_dir.glob(\"*.png\"))\n",
        "print(\"Number of images found: \", len(images))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images found:  1040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwyhJjK0w6wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poyQ0iG4xSwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img_path in images:\n",
        "    label = img_path.name.split('.png')[0]\n",
        "    captcha_length.append(len(label))\n",
        "    dataset.append((str(img_path),label))\n",
        "\n",
        "    for ch in label:\n",
        "        characters.add(ch)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "396CWlLXxuof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort the characters        \n",
        "characters = sorted(characters)\n",
        "\n",
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njOoNkCJxyOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "187af48f-2681-4330-a3a0-cf41ac71454d"
      },
      "source": [
        "\n",
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unqiue charcaters in the whole dataset:  19\n",
            "Maximum length of any captcha:  5\n",
            "Characters present:  ['2', '3', '4', '5', '6', '7', '8', 'b', 'c', 'd', 'e', 'f', 'g', 'm', 'n', 'p', 'w', 'x', 'y']\n",
            "Total number of samples in the dataset:  1040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OSQXbppx2S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b8d2ab32-41f4-47b7-d536-57677c890b09"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>w2yp7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>22d5n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>ng46m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>y7mnm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>ygfwe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            img_path  label\n",
              "0  /content/drive/My Drive/captcha recognition/sa...  w2yp7\n",
              "1  /content/drive/My Drive/captcha recognition/sa...  22d5n\n",
              "2  /content/drive/My Drive/captcha recognition/sa...  ng46m\n",
              "3  /content/drive/My Drive/captcha recognition/sa...  y7mnm\n",
              "4  /content/drive/My Drive/captcha recognition/sa...  ygfwe"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uaTk55SzYC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ad006f0-c310-4104-8daf-fce9d568091c"
      },
      "source": [
        "dataset['img_path'][0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/captcha recognition/samples/w2yp7.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymO4S9YKx508",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = train_test_split(dataset, test_size=0.1, random_state=seed)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHAWGuSyI1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7roDDnPmySzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQdqhFdiyV3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_array(df,resize=True,img_height=50,img_width=200):\n",
        "\n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "\n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df['img_path'][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "\n",
        "        img = (img/255.).astype(np.float32)\n",
        "\n",
        "\n",
        "        label = df[\"label\"][i]    \n",
        "\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "\n",
        "    return images,np.array(labels)        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "venD4_xo0xaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.reset_index(drop=True,inplace=True)\n",
        "X_test.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1yxVgvI09f0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "86d7b3a4-8c1d-4bfa-ceba-3c28b9998bbb"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>6wb76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>44xe8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>7cdge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>xngxc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/My Drive/captcha recognition/sa...</td>\n",
              "      <td>gpnxn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            img_path  label\n",
              "0  /content/drive/My Drive/captcha recognition/sa...  6wb76\n",
              "1  /content/drive/My Drive/captcha recognition/sa...  44xe8\n",
              "2  /content/drive/My Drive/captcha recognition/sa...  7cdge\n",
              "3  /content/drive/My Drive/captcha recognition/sa...  xngxc\n",
              "4  /content/drive/My Drive/captcha recognition/sa...  gpnxn"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2FM59Am0bR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d7ee0268-6885-44ec-ebc4-98ca4032657f"
      },
      "source": [
        "training_data, training_labels = generate_array(df=X_train)\n",
        "print(\"Number of training images: \", training_data.shape)\n",
        "print(\"Number of training labels: \", training_labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training images:  (936, 50, 200)\n",
            "Number of training labels:  (936,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JHjw9Uj0kxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "715fefa2-a7fb-4c90-8ff4-a7f29fa2036a"
      },
      "source": [
        "validation_data, validation_labels = generate_array(df=X_test)\n",
        "print(\"Number of validation images: \", validation_data.shape)\n",
        "print(\"Number of validation labels: \", validation_labels.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of validation images:  (104, 50, 200)\n",
            "Number of validation labels:  (104,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYdf_MnC1BA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size=32,\n",
        "                 img_width=200,\n",
        "                 img_height=50,\n",
        "                 downsample_factor=4,\n",
        "                 max_length=5,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        \n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
        "                               dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "                                (self.img_width // self.downsample_factor - 2)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM687VzG6q9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=200\n",
        "img_height=50 \n",
        "\n",
        "# Factor  by which the image is going to be downsampled\n",
        "# by the convolutional blocks\n",
        "downsample_factor=4\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=5\n",
        "\n",
        "# Get a generator object for the training data\n",
        "train_data_generator = DataGenerator(data=training_data,\n",
        "                                     labels=training_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )\n",
        "\n",
        "# Get a generator object for the validation data \n",
        "valid_data_generator = DataGenerator(data=validation_data,\n",
        "                                     labels=validation_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=False\n",
        "                                    )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvHCShF96ypP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFGSoZ6N62ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
        "                            name='input_data',\n",
        "                            dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "    x = layers.Conv2D(32,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "    \n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
        "                               decay=1e-6,\n",
        "                               momentum=0.9,\n",
        "                               nesterov=True,\n",
        "                               clipnorm=5)\n",
        "    \n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=sgd)\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhMqNTo07QAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "b46ef9a5-b094-4d50-fd5a-84286dfd3b3f"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ocr_model_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_data (InputLayer)         [(None, 200, 50, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 200, 50, 32)  320         input_data[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 100, 25, 32)  0           Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv2 (Conv2D)                  (None, 100, 25, 64)  18496       pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool2 (MaxPooling2D)            (None, 50, 12, 64)   0           Conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 50, 768)      0           pool2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 50, 64)       49216       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 50, 64)       0           dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 50, 256)      197632      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 50, 128)      164352      bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_label (InputLayer)        [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 50, 20)       2580        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "ctc_loss (CTCLayer)             (None, 1)            0           input_label[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 432,596\n",
            "Trainable params: 432,596\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWW_Ee8s7XLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ac24fb3-a520-4a51-c35a-31ddd3d4489b"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   patience=5,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data_generator,\n",
        "                    validation_data=valid_data_generator,\n",
        "                    epochs=50,\n",
        "                    callbacks=[es])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "30/30 [==============================] - 3s 92ms/step - loss: 30.2377 - val_loss: 16.4747\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 16.3760 - val_loss: 16.4775\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 16.3642 - val_loss: 16.5129\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 16.3380 - val_loss: 16.4843\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 16.3541 - val_loss: 16.4383\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 16.3406 - val_loss: 16.4020\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 16.2170 - val_loss: 16.2400\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 16.0553 - val_loss: 16.1664\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 16.0015 - val_loss: 16.1639\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 16.0038 - val_loss: 16.1320\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 15.9594 - val_loss: 16.1344\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 15.9008 - val_loss: 15.8827\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 15.7110 - val_loss: 15.6573\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 15.4463 - val_loss: 15.2514\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 15.0590 - val_loss: 14.9656\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 14.8380 - val_loss: 14.9907\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 14.6205 - val_loss: 14.6242\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 14.4168 - val_loss: 14.5669\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 14.2429 - val_loss: 14.3499\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 14.0461 - val_loss: 14.1069\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 13.7580 - val_loss: 13.9374\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 13.4652 - val_loss: 13.9479\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 13.1910 - val_loss: 13.2524\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 12.9356 - val_loss: 13.0953\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 12.7408 - val_loss: 13.1178\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 12.4853 - val_loss: 12.7626\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 12.2648 - val_loss: 12.4681\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 11.9847 - val_loss: 12.3806\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 11.7327 - val_loss: 12.0806\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 11.5035 - val_loss: 11.8586\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 11.1726 - val_loss: 11.4811\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 10.9052 - val_loss: 11.3464\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 10.7038 - val_loss: 10.9712\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 10.3775 - val_loss: 10.8760\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 10.1015 - val_loss: 10.5797\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 9.7867 - val_loss: 10.2413\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 9.5304 - val_loss: 10.0007\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 9.1883 - val_loss: 9.7734\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 8.9303 - val_loss: 9.3946\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 8.6235 - val_loss: 8.7957\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 8.1917 - val_loss: 8.2326\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 7.6305 - val_loss: 7.5427\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 6.8236 - val_loss: 6.1370\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 6.0630 - val_loss: 5.0981\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 5.1622 - val_loss: 4.0473\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 4.3431 - val_loss: 3.0099\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 3.5918 - val_loss: 2.3732\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 2.9668 - val_loss: 1.8391\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 2.3813 - val_loss: 1.5433\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 1.9625 - val_loss: 1.2518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "basL16fv_8mN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "daad14c1-04b3-40cb-f572-aefa50398ad6"
      },
      "source": [
        "model.save(\"captcha_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZj_3-BeAYnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyGBSxRoAYHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4E14V9kAYDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLspUIMlAZXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5pNH2VtAZJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUZ7qvRR7cP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "3c6554e8-973d-4fb8-84db-861279038eed"
      },
      "source": [
        "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
        "                                        model.get_layer(name='dense2').output)\n",
        "prediction_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_data (InputLayer)      [(None, 200, 50, 1)]      0         \n",
            "_________________________________________________________________\n",
            "Conv1 (Conv2D)               (None, 200, 50, 32)       320       \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 100, 25, 32)       0         \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv2D)               (None, 100, 25, 64)       18496     \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 50, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 50, 768)           0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 50, 64)            49216     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 256)           197632    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 128)           164352    \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 50, 20)            2580      \n",
            "=================================================================\n",
            "Total params: 432,596\n",
            "Trainable params: 432,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAwPahzb7xe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
        "    \n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, \n",
        "                                        input_length=input_len,\n",
        "                                        greedy=True)[0][0]\n",
        "    \n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = ''\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >=0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "    \n",
        "    # return final text results\n",
        "    return output_text"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViLpXuKU8B2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_value_ = valid_data_generator"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUkSZ5tw72hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "81d008ce-d41c-413b-8598-a43f937e572d"
      },
      "source": [
        "#  Let's check results on some validation samples\n",
        "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
        "    bs = inp_value['input_data'].shape[0]\n",
        "    X_data = inp_value['input_data']\n",
        "    labels = inp_value['input_label']\n",
        "    \n",
        "    preds = prediction_model.predict(X_data)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    \n",
        "    \n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "        \n",
        "    for i in range(bs):\n",
        "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
        "    break"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:5871: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "Ground truth: w2n7e \t Predicted: w2n7e\n",
            "Ground truth: wm47f \t Predicted: w47f\n",
            "Ground truth: 8npd5 \t Predicted: 8npd5\n",
            "Ground truth: cnex4 \t Predicted: cnex4\n",
            "Ground truth: p2dw7 \t Predicted: p2dw7\n",
            "Ground truth: d75b5 \t Predicted: d75b5\n",
            "Ground truth: f85y3 \t Predicted: f85y3\n",
            "Ground truth: fg7mg \t Predicted: fg7ng\n",
            "Ground truth: 44ype \t Predicted: 44ype\n",
            "Ground truth: 56m6y \t Predicted: 56m6y\n",
            "Ground truth: 4433m \t Predicted: 4433n\n",
            "Ground truth: men4f \t Predicted: men4f\n",
            "Ground truth: d378n \t Predicted: d378n\n",
            "Ground truth: e3ndn \t Predicted: e3ndn\n",
            "Ground truth: 74853 \t Predicted: 74853\n",
            "Ground truth: gn2xy \t Predicted: gn2xy\n",
            "Ground truth: 4egem \t Predicted: 4egen\n",
            "Ground truth: pg4bf \t Predicted: pg4bf\n",
            "Ground truth: 5bb66 \t Predicted: 5bb66\n",
            "Ground truth: cc845 \t Predicted: cc845\n",
            "Ground truth: n7dyb \t Predicted: n7dyb\n",
            "Ground truth: 368y5 \t Predicted: 368y5\n",
            "Ground truth: yd38e \t Predicted: yd38e\n",
            "Ground truth: pgwnp \t Predicted: pgwnp\n",
            "Ground truth: nfd8g \t Predicted: nfd8g\n",
            "Ground truth: 6cm6m \t Predicted: 6cm6m\n",
            "Ground truth: mcyfx \t Predicted: ncyfx\n",
            "Ground truth: 4ynf3 \t Predicted: 4yf3\n",
            "Ground truth: 4743p \t Predicted: 4743p\n",
            "Ground truth: 53wb8 \t Predicted: 53wb8\n",
            "Ground truth: 37d52 \t Predicted: 37d52\n",
            "Ground truth: w4cdc \t Predicted: w4cdc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7gRNh5V8S8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = inp_value['input_data'].shape[0]\n",
        "X_data = inp_value['input_data']\n",
        "labels = inp_value['input_label']\n",
        "    \n",
        "preds = prediction_model.predict(X_data)\n",
        "pred_texts = decode_batch_predictions(preds)\n",
        "    \n",
        "    \n",
        "orig_texts = []\n",
        "for label in labels:\n",
        "    text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "    orig_texts.append(text)\n",
        "        \n",
        "    print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4zFqtEM8xsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu-uKUHK75Dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9f1d611-63e1-4b37-852a-f79e0c7c5085"
      },
      "source": [
        "X_data"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]]],\n",
              "\n",
              "\n",
              "       [[[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]]],\n",
              "\n",
              "\n",
              "       [[[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]]],\n",
              "\n",
              "\n",
              "       [[[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]]],\n",
              "\n",
              "\n",
              "       [[[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        [[0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         [0.7529412 ],\n",
              "         ...,\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ],\n",
              "         [0.7647059 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        [[0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         [0.9843137 ],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH6G5sbE-ZUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQgX9pzkVqEssG4mofH3DWEN757udJdjd-NMg&usqp=CAU'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0bYxuwc-15f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0f1009f5-679c-46b4-d0df-f2711354f776"
      },
      "source": [
        "img"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=P size=407x124 at 0x7F611E367550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHhgt0tVETdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}